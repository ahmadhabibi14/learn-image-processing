{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black White ::  [[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cv2 import typing\n",
    "\n",
    "img: typing.MatLike = cv2.imread(\"apple_1.jpeg\")\n",
    "\n",
    "# konversi gambar ke grayscale\n",
    "gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# konversi grayscale ke gambar black and white menggunakan binary thresholding\n",
    "( thresh, BnW_image ) = cv2.threshold(gray_image, 125, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# tampilkan semua gambar\n",
    "# cv2.imshow(\"Black white\", BnW_image)\n",
    "# cv2.imshow(\"Plain \", img)\n",
    "# cv2.imshow(\"Grayscale \", gray_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Black White :: \", BnW_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import typing\n",
    "\n",
    "img: typing.MatLike = cv2.imread(\"apple_1.jpeg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "BnW_image = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "total_pixel = BnW_image.count\n",
    "\n",
    "print(\"Black White :: \", BnW_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/habi/Dev/githubRepos/learn-image-processing/.venv/lib/python3.11/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"green_apple.webp\")\n",
    "\n",
    "# Here, you define your target color as\n",
    "# a tuple of three values: RGB\n",
    "green = [130, 158, 0]\n",
    "\n",
    "# You define an interval that covers the values\n",
    "# in the tuple and are below and above them by 20\n",
    "diff = 20\n",
    "\n",
    "# Be aware that opencv loads image in BGR format,\n",
    "# that's why the color values have been adjusted here:\n",
    "boundaries = [([green[2], green[1]-diff, green[0]-diff],\n",
    "           [green[2]+diff, green[1]+diff, green[0]+diff])]\n",
    "\n",
    "# Scale your BIG image into a small one:\n",
    "scalePercent = 0.3\n",
    "\n",
    "# Calculate the new dimensions\n",
    "width = int(img.shape[1] * scalePercent)\n",
    "height = int(img.shape[0] * scalePercent)\n",
    "newSize = (width, height)\n",
    "\n",
    "# Resize the image:\n",
    "img = cv2.resize(img, newSize, None, None, None, cv2.INTER_AREA)\n",
    "\n",
    "# check out the image resized:\n",
    "cv2.imshow(\"img resized\", img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# for each range in your boundary list:\n",
    "for (lower, upper) in boundaries:\n",
    "\n",
    "    # You get the lower and upper part of the interval:\n",
    "    lower = np.array(lower, dtype=np.uint8)\n",
    "    upper = np.array(upper, dtype=np.uint8)\n",
    "\n",
    "    # cv2.inRange is used to binarize (i.e., render in white/black) an image\n",
    "    # All the pixels that fall inside your interval [lower, uipper] will be white\n",
    "    # All the pixels that do not fall inside this interval will\n",
    "    # be rendered in black, for all three channels:\n",
    "    mask = cv2.inRange(img, lower, upper)\n",
    "\n",
    "    # Check out the binary mask:\n",
    "    cv2.imshow(\"binary mask\", mask)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # Now, you AND the mask and the input image\n",
    "    # All the pixels that are white in the mask will\n",
    "    # survive the AND operation, all the black pixels\n",
    "    # will remain black\n",
    "    output = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    # Check out the ANDed mask:\n",
    "    cv2.imshow(\"ANDed mask\", output)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # You can use the mask to count the number of white pixels.\n",
    "    # Remember that the white pixels in the mask are those that\n",
    "    # fall in your defined range, that is, every white pixel corresponds\n",
    "    # to a green pixel. Divide by the image size and you got the\n",
    "    # percentage of green pixels in the original image:\n",
    "    ratio_green = cv2.countNonZero(mask)/(img.size/3)\n",
    "\n",
    "    # This is the color percent calculation, considering the resize I did earlier.\n",
    "    colorPercent = (ratio_green * 100) / scalePercent\n",
    "\n",
    "    # Print the color percent, use 2 figures past the decimal point\n",
    "    print('green pixel percentage:', np.round(colorPercent, 2))\n",
    "\n",
    "    # numpy's hstack is used to stack two images horizontally,\n",
    "    # so you see the various images generated in one figure:\n",
    "    # cv2.imshow(\"images\", np.hstack([img, output]))\n",
    "    # cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
